{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJOJocLee0lw"
      },
      "source": [
        "# SET 3125 Project Outline ---- DC-OPF\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Pd7BE08NzK"
      },
      "source": [
        "## Background of the Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W94sei8R1Xwg"
      },
      "source": [
        "The goal of this project is to develop a machine learning model **to predict the results of a DC Optimal Power Flow (DC-OPF) for a 14-bus power system**. You need to train a supervised learning regression model using historical data generated from DC-OPF solutions (provided already). By doing so, we aim to create a fast and reliable model that can be used in real-time operations, bypassing the need for computationally expensive optimization solvers.\n",
        "\n",
        "The **features** of the dataset are the power demands at different buses while the **labels** are the generator set points that satisfy the optimal power flow conditions.\n",
        "\n",
        "In the following, we provide some background information for DC-OPF, such that you may have a better understanding of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3nzpXt9UoX"
      },
      "source": [
        "### DC-OPF Formulation\n",
        "\n",
        "DC Optimal Power Flow (DC-OPF) is a linearized version of the (AC) Optimal Power Flow problem that is used to determine the optimal operating points of generators in a power system in terms of minimizing generation costs while meeting load demands and adhering to system constraints. The DC-OPF formulation involves:\n",
        "\n",
        "1. **Objective Function**: Minimize the total cost of power generation.\n",
        "  \n",
        "   $$\\min_{P_{G_i}} \\quad \\sum_{i \\in N} C(P_{G_i})=aP_{G_i}$$\n",
        "   Where $ C(P_{G_i})$ is the cost function associated with the power generated by generator $G_i$. The objective is to minimize the total generation cost while ensuring the system operates reliably. Note that if there is no generator connected on bus $i$, then $P_{G_i}=0$.\n",
        "\n",
        "2. **Power Balance Equation**: At each bus, the generated power minus the load demand must be balanced by the net power flow into or out of the bus.\n",
        "   \n",
        "   $$\n",
        "   \\sum_{(i,j)\\in L}F_{ij} = P_{G_i} - P_{D_i}, \\quad \\forall i \\in N\n",
        "  $$\n",
        "   \n",
        "   Here, $F_{ij}$ represents the power flow from bus $i$ to bus $j$ through transmission line $ij$ (*positive* means flows out). $P_{D_i}$ represents the load demand at bus $i$.\n",
        "\n",
        "3. **Power Flow Equations**: Power flow between buses is modeled as a linear function of the voltage angle difference between buses:\n",
        "   \n",
        "   $$\n",
        "   F_{ij} = B_{ij} (\t\\theta_i - \t\\theta_j), \\quad \\forall (i, j) \\in L\n",
        "   $$\n",
        "   \n",
        "   Where $ B_{ij} $ is the susceptance of the line between bus $ i $ and bus $ j $, and $ \t\\theta_i - \t\\theta_j $ represents the voltage angle difference. This equation is used to calculate the power flowing on the transmission lines.\n",
        "\n",
        "4. **Flow Limits**: Each transmission line has a power flow limit that must not be exceeded to ensure system security:\n",
        "   \n",
        "   $$\n",
        "   F_{ij}^{\t\\text{min}}\\leq F_{ij} \\leq F_{ij}^{\t\\text{max}}, \\quad \\forall (i, j) \\in L$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raQCkq0Ge0lx"
      },
      "source": [
        "## Basic Workflow with Fully Connected Neural Network (FNN)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvZ8jXsz6Lka"
      },
      "source": [
        "### 0. Import and install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr9KlVWObel9"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install gurobipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5iRfOgd_Wh-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as pyg\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib\n",
        "import networkx as nx\n",
        "import math\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch_geometric.nn import ChebConv, GraphConv, GCNConv\n",
        "from torch.nn import Linear\n",
        "from torch.nn import Parameter\n",
        "from itertools import product\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njd9oDsPAO5Y"
      },
      "source": [
        "### 1. Dataset loading, inspection, and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-3Qt4TjbYDG"
      },
      "outputs": [],
      "source": [
        "# Mount google drive if you use google colab, otherwise comment out this cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emcOxUVT_ZWk"
      },
      "outputs": [],
      "source": [
        "# Load the dataset by inserting your file directory\n",
        "load_demand = np.load('')\n",
        "generator_supply = np.load('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY5PKVvjLrup"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "\n",
        "*   check the distributions of the load demands and gnerator supplies, are there outliers? Comment on how you would remove them if any\n",
        "*   Look at the total demand for each data sample each sample, does it match total supply?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THItx_M280oT"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDCQResj80wC"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQWPO51bFWDe"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Training on GPU\")\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  print(\"Training on CPU\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8_IiId-e0ly"
      },
      "source": [
        "### 2. Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "021Addr5qfmB"
      },
      "source": [
        "A tutorial on defining a NN with torch: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfXvcUClp4MK"
      },
      "outputs": [],
      "source": [
        "# Define the model, e.g., with torch write a simple feedforward network\n",
        "class FF_DNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim,num_layers):\n",
        "        super(FF_DNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim=hidden_dim\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        for _ in range(num_layers-1):\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.model(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f2tpwaHe0ly"
      },
      "source": [
        "### 3. Functions\n",
        "\n",
        "- dataset spliting function\n",
        "- loss function\n",
        "- training function (train)\n",
        "- validation function (eval)\n",
        "- test function (test)\n",
        "- Hyperparameter multiple run function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SredIR32rK9R"
      },
      "outputs": [],
      "source": [
        "# dataset splitting function, we use ratio [66.6:16.6:16.6]\n",
        "def split_data(x_data,y_data):\n",
        "\n",
        "  train_size = int((x_data.shape[0]//3) * 2)\n",
        "  val_size = int((x_data.shape[0]//3) / 2)\n",
        "  test_size = int((x_data.shape[0]//3) / 2)\n",
        "\n",
        "  train_x = x_data[:train_size,:]\n",
        "  val_x = x_data[train_size:train_size+val_size,:]\n",
        "  test_x = x_data[train_size+val_size:,:]\n",
        "\n",
        "  train_y = y_data[:train_size,:]\n",
        "  val_y = y_data[train_size:train_size+val_size,:]\n",
        "  test_y = y_data[train_size+val_size:,:]\n",
        "\n",
        "  return train_x, val_x, test_x , train_y, val_y, test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X7-OW3SrU_b"
      },
      "outputs": [],
      "source": [
        "# we define a simple loss function\n",
        "def simple_loss(y_pred, y):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLMajCVjre4H"
      },
      "outputs": [],
      "source": [
        "# model training function\n",
        "def train_fnn(model, loader, criterion, optimizer, device=device):\n",
        "    model.to(device)\n",
        "    model.train() # specifies that the model is in training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for x,y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXtNDZY0roC8"
      },
      "outputs": [],
      "source": [
        "# model evaluation function\n",
        "@torch.no_grad()\n",
        "def evaluate_fnn(model, loader, criterion, device=device):\n",
        "    model.to(device)\n",
        "    model.eval() # specifies that the model is in evaluation mode\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhDgyG3mrtcO"
      },
      "outputs": [],
      "source": [
        "# model testing function\n",
        "\n",
        "def test_fnn(model, loader, criterion, device=device):\n",
        "    model.to(device)\n",
        "    model.eval() # specifies that the model is in evaluation mode\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "\n",
        "    model_preds = []\n",
        "    actual_y = []\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            model_preds.append(y_pred)\n",
        "            actual_y.append(y)\n",
        "            loss = criterion(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    return epoch_loss / len(loader), model_preds,actual_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of9WAFWD2XQe"
      },
      "outputs": [],
      "source": [
        "# simple  function to create multiple run instances of model training for best hyperparameter selection\n",
        "\n",
        "def create_hyper_combination_FNN(h_feat, l_feat):\n",
        "    parameters = dict(\n",
        "      hid_features= h_feat,\n",
        "      num_layers= l_feat\n",
        "  )\n",
        "\n",
        "    param_values = [v for v in parameters.values()]\n",
        "    print(param_values)\n",
        "\n",
        "    for  hid_features, num_layers in product(*param_values):\n",
        "        print(hid_features, num_layers)\n",
        "\n",
        "    return param_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rIFHKQDe0lz"
      },
      "source": [
        "### 4. Training setup\n",
        "\n",
        "Execute dataset split and specify batchsize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFAaNBmutNBZ"
      },
      "outputs": [],
      "source": [
        "# Convert data to torch tensors and split the dataset\n",
        "x_data = torch.tensor(load_demand).float()\n",
        "y_data = torch.tensor(generator_supply).float()\n",
        "\n",
        "train_x, val_x, test_x , train_y, val_y, test_y = split_data(x_data, y_data)\n",
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "val_dataset = TensorDataset(val_x, val_y)\n",
        "test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "batch_size=16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-XEJHggPm6x"
      },
      "source": [
        "#### Here is an example standard FNN model training. We:\n",
        "\n",
        "- perform the loop over a specified number of epochs\n",
        "- optimiser setup\n",
        "- NN model instantiation\n",
        "- Print output / plot training progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m6TxNcNP0sY"
      },
      "outputs": [],
      "source": [
        "# specify the model input and output dimensions\n",
        "N_input_features = 14\n",
        "N_output_features = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FEUYlsdPSUy"
      },
      "outputs": [],
      "source": [
        "# create a model instance and train model for one run, model hyperparameters are fixed as 16 and 4 here\n",
        "model = FF_DNN(N_input_features, 16, N_output_features,4)\n",
        "\n",
        "# specify optimizer and other model details\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "best_valid_loss = float('inf')\n",
        "early_stop_thresh = 20\n",
        "epochs = 50\n",
        "best_epoch = -1\n",
        "for epoch in range(epochs+1):\n",
        "  train_loss = train_fnn(model, train_loader, simple_loss, optimizer)\n",
        "  valid_loss = evaluate_fnn(model, val_loader, simple_loss)\n",
        "  training_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "\n",
        "  scheduler.step(valid_loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "      print(f'Epoch: {epoch}')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "\n",
        "training_losses=np.array(training_losses)\n",
        "validation_losses=np.array(validation_losses)\n",
        "\n",
        "plt.subplots(figsize=(5,3))\n",
        "plt.plot([i for i in range(len(training_losses))], training_losses, 'r', label='Training loss')\n",
        "plt.plot([i for i in range(len(validation_losses))], validation_losses, 'g', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.title(f'FNN Training and Validation loss for 14 Bus system',fontsize = 15)\n",
        "plt.xlabel('Epochs',fontsize = 12)\n",
        "plt.ylabel('MSE Loss',fontsize = 12)\n",
        "plt.semilogy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce48oFz3e0lz"
      },
      "source": [
        "### 5. Training with hyperparameter combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3sQH-mKOjxV"
      },
      "source": [
        "### Task 5\n",
        "\n",
        "\n",
        "\n",
        "1.   Use the different hyperparameter combinations we have provided with 'create_hyper_combination_FNN' function above to create 6 runs\n",
        "\n",
        "2.   Comment on the influence of model hyperparameters on the model accuracy\n",
        "\n",
        "3. Use the model with the best hyperparameter combination for subsequent evaluations\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lHY_2izxLSg"
      },
      "outputs": [],
      "source": [
        "## insert the rest of your code here\n",
        "\n",
        "h_feat = [32, 64]\n",
        "l_feat = [2, 3, 4]\n",
        "\n",
        "# specify the hyperparameter selections\n",
        "param_values = # insert code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVDLztfExExX"
      },
      "outputs": [],
      "source": [
        "# insert code here\n",
        "trained_models = []\n",
        "\n",
        "for run_number, (hidden_dim,num_layers) in enumerate(product(*param_values)):\n",
        "  print(\"run number:\", run_number + 1)\n",
        "\n",
        "  #create simple model instance\n",
        "\n",
        "\n",
        "  # specify optimizer and other model details\n",
        "\n",
        "\n",
        "  training_losses = []\n",
        "  validation_losses = []\n",
        "  best_valid_loss = float('inf')\n",
        "  early_stop_thresh = 20\n",
        "  epochs = 50\n",
        "  best_epoch = -1\n",
        "  # insert code here, follow the same structure as example training\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  test_loss, model_preds,actual_y = test_fnn(model, test_loader, simple_loss)\n",
        "\n",
        "  trained_models.append(model)\n",
        "  print(\"test loss:\", np.array(test_loss))\n",
        "\n",
        "print('finished all runs with different hyperparameters!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT5bzvh8e0lz"
      },
      "source": [
        "### 6. Understand predictions\n",
        "\n",
        "To ensure the model is working as we would expect, perform the following sanity checks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_jFh6bBMu_p"
      },
      "source": [
        "### Task 6\n",
        "\n",
        "\n",
        "*   plot an histogram of prediction errors, what type of distribution do you obtain?\n",
        "*   For the test data, plot the mismatch between the sum of demands and sum of predicted generator supply? What is the maximum mismatch? What is the mean mismatch?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwRdBiACH9Z8"
      },
      "outputs": [],
      "source": [
        "# plot an histogram of the error distribution\n",
        "#add your code here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr3o9jd2HUjM"
      },
      "outputs": [],
      "source": [
        "# Function to compute the total power demand minus the total power injection.\n",
        "def compute_power_balance_mismatch(x, y):\n",
        "  #insert code here\n",
        "  return power_balance_mismatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psV4Pq2-HUwn"
      },
      "outputs": [],
      "source": [
        "# add code to compute the maximum and mean power balance mismatch between the load demand and true generator supply here. HINT - values should be very close to zero\n",
        "max_power_balance_error = #insert code here\n",
        "mean_power_balance_error = # insert code here\n",
        "print(max_power_balance_error, mean_power_balance_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExwqVa0FH3e9"
      },
      "outputs": [],
      "source": [
        "# add code to compute the maximum and mean power balance mismatch between the load demand and predicted generator supply here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCdBcgVTQd83"
      },
      "outputs": [],
      "source": [
        "# add your code for line plot of mismatch here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdY9D8z2e0lz"
      },
      "source": [
        "## Physics-Informed Training\n",
        "\n",
        "In this section, we will investigate how we can include physics in the training process and how it affects the training performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmtaTuFRIYpU"
      },
      "source": [
        "### 1. The underlying physics\n",
        "\n",
        "We have seen how much the previous model obeys the underlying physics, which requires that the sum of total demand should match the sum of total supply. Now we would define a physics loss to improve the satisfaction of the power balance constraint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9wsNL0PKf8G"
      },
      "outputs": [],
      "source": [
        "# we define a weight for physics loss here\n",
        "\n",
        "physics_loss_weight = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVl9elbZK2a5"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "Write the physics informed loss function using the power balance mismatch function provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owPfrCzFJXEP"
      },
      "outputs": [],
      "source": [
        "# we define physics loss, add code here\n",
        "def extra_loss(x, y_pred):\n",
        "  # insert code here\n",
        "  phy_loss = # insert code here\n",
        "  return phy_loss * physics_loss_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B88RGSaIe0lz"
      },
      "source": [
        "### 2. Adapt functions\n",
        "\n",
        "To include the physics in the training process, we adapt the train_epoch and evaluate_epoch functions by adding the physics-informed loss term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trIcTCh2J2xa"
      },
      "outputs": [],
      "source": [
        "# adjust the training function to include the physics\n",
        "def train_fnn_with_physics(model, loader, criterion, extra_loss, optimizer, device=device):\n",
        "    model.to(device)\n",
        "    model.train() # specifies that the model is in training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for x,y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        data_loss = criterion(y_pred, y)\n",
        "        physics_loss = extra_loss(x, y_pred)\n",
        "        loss = data_loss + physics_loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGz-wR43KToz"
      },
      "outputs": [],
      "source": [
        "# adjust the evaluation function to include the physics\n",
        "@torch.no_grad()\n",
        "def evaluate_fnn_with_physics(model, loader, criterion, extra_loss, device=device):\n",
        "    model.to(device)\n",
        "    model.eval() # specifies that the model is in evaluation mode\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            data_loss = criterion(y_pred, y)\n",
        "            physics_loss = extra_loss(x, y_pred)\n",
        "            loss = data_loss + physics_loss\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMPOrKAqe0lz"
      },
      "source": [
        "### 3. Training\n",
        "\n",
        "To perform the training, we only need to exchange the training and validation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdaDfepOKAiv"
      },
      "outputs": [],
      "source": [
        "trained_models_with_physics = []\n",
        "\n",
        "\n",
        "\n",
        "#create simple model instance\n",
        "model = FF_DNN(N_input_features, hidden_dim, N_output_features,num_layers)\n",
        "\n",
        "# specify optimizer and other model details\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "validation_losses_without_physics = []\n",
        "best_valid_loss = float('inf')\n",
        "early_stop_thresh = 20\n",
        "epochs = 50\n",
        "best_epoch = -1\n",
        "for epoch in range(epochs+1):\n",
        "  train_loss = train_fnn_with_physics(model, train_loader, simple_loss,extra_loss, optimizer)\n",
        "  valid_loss = evaluate_fnn_with_physics(model, val_loader, simple_loss,extra_loss)\n",
        "  valid_loss_without_physics = evaluate_fnn(model, val_loader, simple_loss)\n",
        "  training_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "  validation_losses_without_physics.append(valid_loss_without_physics)\n",
        "\n",
        "  scheduler.step(valid_loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "      print(f'Epoch: {epoch}')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} -- without physics: {valid_loss_without_physics:.3f}')\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "\n",
        "training_losses=np.array(training_losses)\n",
        "validation_losses=np.array(validation_losses)\n",
        "validation_losses_without_physics = np.array(validation_losses_without_physics)\n",
        "\n",
        "plt.subplots(figsize=(5,3))\n",
        "plt.plot([i for i in range(len(training_losses))], training_losses, 'r', label='Training loss')\n",
        "plt.plot([i for i in range(len(validation_losses))], validation_losses, 'g', label='Validation loss')\n",
        "plt.plot([i for i in range(len(validation_losses_without_physics))], validation_losses_without_physics, 'g--', label='Validation loss without physics')\n",
        "plt.legend()\n",
        "plt.title(f'FNN Training and Validation loss for 14 Bus system with Physics',fontsize = 15)\n",
        "plt.xlabel('Epochs',fontsize = 12)\n",
        "plt.ylabel('MSE Loss',fontsize = 12)\n",
        "plt.semilogy()\n",
        "\n",
        "test_loss, model_preds,actual_y = test_fnn(model, test_loader, simple_loss)\n",
        "\n",
        "trained_models_with_physics.append(model)\n",
        "print(\"test loss:\", np.array(test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55yI_BOre0lz"
      },
      "source": [
        "### 4. Understand the effect of the physics regularisation\n",
        "\n",
        "As we did in the previous section, we check again how well the physics are satisfied and the effect on the prediction error distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKKzGwyolkEq"
      },
      "source": [
        "### Task 4\n",
        "\n",
        "1.   Check how well the power balance constraint is satisfied now with the physics loss included by computing the maximum and mean power balance mismatches\n",
        "2.   Plot the error distribution and comment on the type of distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqoVs7XpOQWV"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLr5KkQPOSpd"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1iwLCnOe0lz"
      },
      "source": [
        "## GNN Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPvPmRfERPen"
      },
      "source": [
        "### 1. Load network topology data and create graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khgenhyyqgBf"
      },
      "outputs": [],
      "source": [
        "# insert file path for the network data file, this is an xlsx file.\n",
        "data_file = # insert file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmV2EZT0nn75"
      },
      "outputs": [],
      "source": [
        "# first we need to import the network data to understand how the power grid graph looks like\n",
        "\n",
        "def read_data(File='IEEE_14_bus_Data.xlsx',print_data=False,DemFactor=1.0,LineLimit=1.0):\n",
        "    # read the data file and convert it into a dictionary of dataframes\n",
        "\n",
        "    Sbase=100\n",
        "\n",
        "    data={}\n",
        "\n",
        "    Bus=pd.read_excel(File,sheet_name='Bus',skiprows=0,index_col=[0],usecols='A')\n",
        "    Bus=list(Bus.index)\n",
        "\n",
        "    branch=pd.read_excel(File,sheet_name='Branch',skiprows=1,index_col=[0,1,2],usecols='A:F')\n",
        "    line=pd.read_excel(File,sheet_name='Branch',skiprows=1,index_col=0,usecols='A')\n",
        "    line=list(line.index)\n",
        "\n",
        "    branch['limit']=(LineLimit*branch['limit'])/Sbase\n",
        "\n",
        "    br_list=list(branch.index)\n",
        "    Lines=gp.tuplelist(br_list)\n",
        "\n",
        "    data['Bus']=Bus\n",
        "    data['branch']=branch\n",
        "    data['Lines']=Lines\n",
        "    data['line']=line\n",
        "\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYz68euenoIt"
      },
      "outputs": [],
      "source": [
        "data_x_bus = read_data(File=data_file,DemFactor=1.0,print_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or1kLEvinoTQ"
      },
      "outputs": [],
      "source": [
        "# function to build networkx graph from adjacency matrix\n",
        "def Build_graph(data,weighted=False):\n",
        "\n",
        "    nodes=data['Bus']\n",
        "    Lines=data['Lines']\n",
        "\n",
        "    node_list=nodes.copy()\n",
        "\n",
        "    graph=nx.Graph()\n",
        "\n",
        "    if weighted==False:\n",
        "        edge_list=[]\n",
        "        for l,i,j in Lines:\n",
        "            graph.add_edge(i, j, weight=1)\n",
        "\n",
        "        graph.add_nodes_from(node_list)\n",
        "\n",
        "    if weighted==True:\n",
        "        edge_list=[]\n",
        "        for l,i,j in Lines:\n",
        "            graph.add_edge(i, j, weight=data['branch'].loc[(l,i,j)]['x'])\n",
        "\n",
        "        graph.add_nodes_from(node_list)\n",
        "        graph.add_edges_from(edge_list)\n",
        "\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcZ8Tq5MnoV2"
      },
      "outputs": [],
      "source": [
        "graph=Build_graph(data_x_bus, weighted=False)\n",
        "nx.draw_networkx(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5LfIjTLSwlO"
      },
      "source": [
        "### 2. Create GNN Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKV2XBsznoYq"
      },
      "outputs": [],
      "source": [
        "#function to create graph datasets\n",
        "\n",
        "def create_graph_data(graph,input_x,output_x, edge_list):\n",
        "\n",
        "    dataset = []\n",
        "    edge_list = [[edge[0], edge[1]] for edge in edge_list]\n",
        "    edge_list = torch.tensor(np.array(edge_list).T, dtype=torch.int64)\n",
        "\n",
        "    for i in range(input_x.shape[0]):\n",
        "            dataset.append(Data(x=input_x[i].float(), y=output_x[i].float(), edge_index=edge_list))\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOT5FajPUUhU"
      },
      "outputs": [],
      "source": [
        "## create edge attributes for network\n",
        "edge_labels = nx.get_edge_attributes(graph, \"weight\")\n",
        "edge_list = [i for i in edge_labels.keys() ]\n",
        "\n",
        "edge_list = [(i[0][1:], i[1][1:]) for i in edge_list]\n",
        "edge_list = [(int(i[0])-1, int(i[1])-1) for i in edge_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtJk1TS-UVmn"
      },
      "outputs": [],
      "source": [
        "train_dataset = create_graph_data(graph,train_x, train_y,edge_list)\n",
        "val_dataset = create_graph_data(graph,val_x, val_y,edge_list)\n",
        "test_dataset = create_graph_data(graph,test_x, test_y,edge_list)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAdQivvHnobw"
      },
      "outputs": [],
      "source": [
        "# Function to create a simple GNN, the output of convolutional layers are passed through linear layers to get the correct output shape\n",
        "class VanillaGNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, network_size, num_features, num_of_outputs,conv_hid_features=32, lin_hid_features=256):\n",
        "        super(VanillaGNN, self).__init__()\n",
        "        self.network_size = network_size\n",
        "        self.num_features = num_features\n",
        "        self.conv_hid_features = conv_hid_features\n",
        "        self.lin_hid_features = lin_hid_features\n",
        "        self.output_dim = num_of_outputs\n",
        "\n",
        "\n",
        "        self.conv1 = ChebConv(self.num_features, self.conv_hid_features, K=3)\n",
        "        self.conv2 = ChebConv(self.conv_hid_features, self.conv_hid_features, K=3)\n",
        "        self.conv3 = ChebConv(self.conv_hid_features, self.conv_hid_features, K=3)\n",
        "\n",
        "\n",
        "        self.lin1 = Linear(self.conv_hid_features*(self.network_size), self.lin_hid_features)\n",
        "        self.lin2 = Linear(self.lin_hid_features,self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x = data.x[:]\n",
        "\n",
        "        x = x.reshape(-1,1)\n",
        "\n",
        "        edge_index = data.edge_index\n",
        "        batch_size = int(len(data.batch)/self.network_size)\n",
        "\n",
        "        x = self.conv1(x=x, edge_index=edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x=x, edge_index=edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        x=x.reshape(batch_size,-1)\n",
        "\n",
        "        x = self.lin1(x)\n",
        "\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        output = torch.flatten(x)\n",
        "\n",
        "        output = output.float()\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbmu_-FXTB-h"
      },
      "source": [
        "### 3. Adapt functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FABynFKYnofD"
      },
      "outputs": [],
      "source": [
        "# function to train GNN model , returns loss per epoch after summing loss per batch and dividing by number of batches in data loader object.\n",
        "def train_gnn(model, loader, optimizer, device=device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        data = batch.to(device)\n",
        "        y = batch.y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        y_pred = y_pred.to(device)\n",
        "        loss = simple_loss(y_pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtr6r28Onok9"
      },
      "outputs": [],
      "source": [
        "# function for model evaluation\n",
        "def evaluate_gnn(model, loader, device=device):\n",
        "\n",
        "\n",
        "    torch.no_grad()\n",
        "    model.to(device)\n",
        "    model.eval() # specifies that the model is in evaluation mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in loader:\n",
        "\n",
        "            data = batch.to(device)\n",
        "            y = batch.y.to(device)\n",
        "            y_pred = model(data)\n",
        "            y_pred = y_pred.to(device)\n",
        "            loss = simple_loss(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHYUqiDPwyNF"
      },
      "outputs": [],
      "source": [
        "# function to run trained model through test data\n",
        "def test_gnn(model, loader, device=device):\n",
        "\n",
        "    torch.no_grad()\n",
        "    model.to(device)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model_preds = []\n",
        "    actual_y = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in loader:\n",
        "\n",
        "            data = batch.to(device)\n",
        "            y = batch.y.to(device)\n",
        "            actual_y.append(y)\n",
        "            y_pred = model(data)\n",
        "            model_preds.append(y_pred)\n",
        "            y_pred = y_pred.to(device)\n",
        "            loss = simple_loss(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader), model_preds, actual_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ9epo1Ie0lz"
      },
      "source": [
        "### 4. Training\n",
        "\n",
        "Here we train the GNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlSUADf2vmas"
      },
      "source": [
        "### 4. Task\n",
        "\n",
        "Train the model using the functions above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9SmwkFCwC8A"
      },
      "outputs": [],
      "source": [
        "trained_gnn_models = []\n",
        "\n",
        "\n",
        "#create simple model instance\n",
        "\n",
        "\n",
        "# specify optimizer and other model details\n",
        "\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "best_valid_loss = float('inf')\n",
        "early_stop_thresh = 20\n",
        "epochs = 50\n",
        "best_epoch = -1\n",
        "# insert code here, follow same structure as previous sections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOOS-l0wWGWH"
      },
      "source": [
        "### 5. Understand predictions\n",
        "\n",
        "To ensure the model is working as we would expect, perform the following sanity checks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCI74k33e0lz"
      },
      "source": [
        "### Task 5\n",
        "\n",
        "1.   Finally for the GNN model, check how well the power balance constraint is satisfied by computing the maximum and mean power balance mismatches\n",
        "2.   Plot the error distribution and comment on the type of distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaAvw9IEWV-M"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAAt51QFWWJq"
      },
      "outputs": [],
      "source": [
        "# insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSrrsk35e0l0"
      },
      "source": [
        "### 6. Compare models\n",
        "\n",
        "Compare the best FNN model from the previous section to the GNN model here based on the number of parameters the models have. Use the function provided below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eUcJ1Gsx0zx"
      },
      "outputs": [],
      "source": [
        "# count the number of parameters in a model\n",
        "def count_model_parameters(model):\n",
        "  tot_params = 0\n",
        "  for parameter in model.parameters():\n",
        "      layer_ws = 1\n",
        "      for val in parameter.shape:\n",
        "          layer_ws*=val\n",
        "      tot_params += layer_ws\n",
        "  print(f\"Total number of parameters = {tot_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdwcydzeyX9I"
      },
      "source": [
        "### Task 6\n",
        "Which of the two models is more parameter efficient?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYXaP2_wyMZx"
      },
      "outputs": [],
      "source": [
        "# add your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmvwFqHxyMi2"
      },
      "outputs": [],
      "source": [
        "# add your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1yAKutIOwFn"
      },
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}